# 交叉验证

解决了我对交叉验证一直存在的一个疑惑：

> K 折交叉验证将会构建 K 份训练集/验证集，因此将产生 K 个训练好的模型，那么选择哪个作为最终模型呢？

上结论：实际上，交叉验证产生的所有的模型实例（这里不能称作模型）都不会作为最终模型。

首先，我们明确一下模型的概念。我们所指的模型是，一种特定的描述输入数据与预测输出数据是如何关联的方法，而不是该方法的不同实例。因此，你可以把线性回归模型和决策树模型称为不同模型，但对于不同的数据集训练出来的不同的模型实例，是不能称作不同模型的。

其次，交叉验证的目的是模型评估，并不是模型构建。因此交叉验证能告诉我们，对于当前数据集，不同模型中哪个模型的性能比较好。举个例子，对于当前数据，我们有两个模型，分别是线性回归模型和决策树模型，这两个模型哪个的性能会比较好呢？交叉验证能够告诉我们答案。

最后，要明确的一点是，我们在使用交叉验证之后，实际上依然需要使用所有数据集作为训练集，训练模型，最终使用该模型做预测。

## 参考文献

- ["机器学习中模型评估与选择中的几个小问题 &#8211; Blogs@WHU-CVRS"](http://cvrs.whu.edu.cn/blogs/?p=154)
- ["How to choose a predictive model after k-fold cross-validation? - Cross Validated"](https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation)